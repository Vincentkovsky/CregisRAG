# CregisRAG 配置文件

# 应用设置
app:
  name: CregisRAG
  host: 0.0.0.0
  port: 8000
  debug: true
  environment: development  # development, production
  log_level: INFO
  cors_origins:
    - http://localhost:3000
    - http://localhost:8000
  
# 认证设置
auth:
  enabled: false  # 设置为true启用认证
  secret_key: "YOUR_SECRET_KEY"
  token_expire_minutes: 60

# 数据处理设置
ingest:
  # 文档解析设置
  parser:
    supported_formats:
      - pdf
      - txt
      - docx
      - html
      - md
    pdf_ocr_enabled: false
    max_file_size_mb: 50
  
  # 文本分块设置
  chunker:
    chunk_size: 1000
    chunk_overlap: 200
    split_by: paragraph  # paragraph, sentence, fixed
    min_chunk_size: 100
    
  # 数据清洗设置
  cleaner:
    remove_urls: true
    remove_emails: true
    remove_line_breaks: true
    normalize_whitespace: true
    remove_special_chars: false

# 嵌入设置
embedding:
  model: sentence-transformers/all-MiniLM-L6-v2  # 替换为您想使用的模型
  batch_size: 32
  dimensions: 384
  normalize: true
  cache_enabled: true
  parallel_processes: 4

# 向量数据库设置
vectordb:
  provider: chroma  # chroma, milvus, pinecone, weaviate
  
  # Chroma设置
  chroma:
    persist_directory: ./data/chroma
    collection_name: cregis_documents
  
  # Milvus设置 (如果使用)
  milvus:
    host: localhost
    port: 19530
    collection_name: cregis_documents
  
  # Pinecone设置 (如果使用)
  pinecone:
    api_key: "YOUR_PINECONE_API_KEY"
    environment: "us-west1-gcp"
    index_name: cregis-index
  
  # Weaviate设置 (如果使用)
  weaviate:
    url: "http://localhost:8080"
    api_key: null  # 如果有的话
    class_name: CregisDocument

# LLM设置
llm:
  provider: openai  # openai, anthropic, local, huggingface

  #DeepSeek设置
  deepseek:
    api_key: "sk-606f8100155f42a6a2e5af2b0c2d84b8"
    model: deepseek-chat
    temperature: 0.2
    max_tokens: 1000
    timeout_seconds: 30
  
  # OpenAI设置
  openai:
    api_key: "YOUR_OPENAI_API_KEY"
    model: gpt-4-turbo
    temperature: 0.2
    max_tokens: 1000
    timeout_seconds: 30
  
  # Anthropic设置
  anthropic:
    api_key: "YOUR_ANTHROPIC_API_KEY"
    model: claude-3-sonnet-20240229
    temperature: 0.2
    max_tokens: 1000
    timeout_seconds: 30
  
  # 本地模型设置 (如果使用)
  local:
    model_path: "./models/llama-3-8b"
    device: cuda  # cpu, cuda
    max_new_tokens: 1000
    temperature: 0.2

# 检索设置
retrieval:
  top_k: 5
  similarity_threshold: 0.7
  use_reranking: true
  reranking_model: cross-encoder/ms-marco-MiniLM-L-6-v2
  retrieval_method: similarity  # similarity, mmr, hybrid
  mmr_lambda: 0.5  # 用于MMR方法，平衡相关性和多样性

# 提示模板设置
prompts:
  system_template: |
    你是一个基于知识库的智能助手。你可以回答与提供的上下文信息相关的问题。
    如果问题无法从上下文中回答，请诚实地表明你不知道，不要编造信息。
    始终引用回答中使用的信息来源。
    
  query_template: |
    上下文信息：
    {context}
    
    用户问题：
    {query}
    
    请根据上述上下文信息回答用户问题。如果上下文信息不足以回答，请直接表明无法回答，不要编造内容。

# 前端设置
frontend:
  title: CregisRAG知识助手
  description: 智能检索增强生成系统
  theme: light  # light, dark, auto
  results_per_page: 10
  enable_source_preview: true
  
# 存储设置
storage:
  data_dir: ./data
  raw_dir: ./data/raw
  processed_dir: ./data/processed
  embeddings_dir: ./data/embeddings
  backup_enabled: true
  backup_interval_hours: 24
  max_backups: 7 